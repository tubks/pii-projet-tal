{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from datasets import Dataset\n",
    "from functools import reduce\n",
    "from seqeval.metrics import recall_score, precision_score\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "from functools import partial\n",
    "\n",
    "# add the parent directory to the path so we can import the dataloader module\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from src.data.dataloader import preprocess_data, get_dataset_from_path, get_train_val_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo: add more loops to the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    LABELS_LIST = ['B-NAME_STUDENT', 'B-EMAIL', 'B-USERNAME', 'B-ID_NUM', 'B-PHONE_NUM', 'B-URL_PERSONAL', 'B-STREET_ADDRESS', 'I-NAME_STUDENT', 'I-EMAIL', 'I-USERNAME', 'I-ID_NUM', 'I-PHONE_NUM','I-URL_PERSONAL','I-STREET_ADDRESS', 'O']\n",
    "    label2id = {label: i for i, label in enumerate(LABELS_LIST)}\n",
    "    label2id['[PAD]'] = -100\n",
    "    id2label = {i: label for label, i in label2id.items()}\n",
    "    seed = 42\n",
    "\n",
    "    # model checkpoint\n",
    "    model_name = 'microsoft/deberta-base'\n",
    "    train_head_only = True\n",
    "\n",
    "    # path to the directory where the model will be saved\n",
    "    local_path = os.path.abspath(os.path.abspath(''))\n",
    "    target_dir = os.path.join(local_path,'..','models', 'deberta-base')\n",
    "\n",
    "    #training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=os.path.join(target_dir, 'trainer'), \n",
    "        evaluation_strategy=\"epoch\",\n",
    "        per_device_train_batch_size=4,\n",
    "        )\n",
    "    model_save_path = os.path.join(target_dir, 'model')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(CFG.model_name, add_prefix_space=True, use_fast=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoding the labels...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d457755297f4827aa38b20c53b20b9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6807 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizing and aligning...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8325f8972ed406dbf20dbff559e0fb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6807 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flattening the data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:07<00:00,  1.28s/it]\n"
     ]
    }
   ],
   "source": [
    "keys_to_flatten = ['labels', 'input_ids', 'attention_mask', 'org_word_ids','document']\n",
    "data_path = os.path.join('..','data', 'raw', 'train.json')\n",
    "data = get_dataset_from_path(data_path)\n",
    "data = preprocess_data(data, tokenizer, label2id = CFG.label2id, keys_to_flatten=keys_to_flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fbeta_score(precision, recall, beta=5.0):\n",
    "        b2 = beta ** 2\n",
    "        return (1 + b2) * ((precision * recall) / (b2 * precision + recall))\n",
    "\n",
    "def compute_metrics(p, labels_list):\n",
    "        predictions, labels = p\n",
    "        predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "        # Remove ignored index (special tokens)\n",
    "        \n",
    "        true_predictions = [\n",
    "            [labels_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "            for prediction, label in zip(predictions, labels)\n",
    "        ]\n",
    "        true_labels = [\n",
    "            [labels_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "            for prediction, label in zip(predictions, labels)\n",
    "        ]\n",
    "\n",
    "        recall = recall_score(true_labels, true_predictions)\n",
    "        precision = precision_score(true_labels, true_predictions)\n",
    "        fbeta_score = get_fbeta_score(precision, recall)\n",
    "\n",
    "        results = {\n",
    "            'recall': recall,\n",
    "            'precision': precision,\n",
    "            'fbeta_score': fbeta_score\n",
    "            }\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaForTokenClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    CFG.model_name, num_labels=len(CFG.id2label), id2label=CFG.id2label, label2id=CFG.label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training head only\n"
     ]
    }
   ],
   "source": [
    "# Freezing the DeBERTa layers\n",
    "if CFG.train_head_only:\n",
    "    print('Training head only')\n",
    "    for param in model.base_model.parameters():\n",
    "        param.requires_grad = False\n",
    "else:\n",
    "    print('Training all layers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_eval, data_test = get_train_val_test_split(data, seed=CFG.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/projet-en-tal/lib/python3.11/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc6b6c25369a47c2b051890f3540402d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8580 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6205, 'learning_rate': 4.708624708624709e-05, 'epoch': 0.17}\n",
      "{'loss': 0.0151, 'learning_rate': 4.4172494172494175e-05, 'epoch': 0.35}\n",
      "{'loss': 0.0092, 'learning_rate': 4.125874125874126e-05, 'epoch': 0.52}\n",
      "{'loss': 0.0093, 'learning_rate': 3.834498834498835e-05, 'epoch': 0.7}\n",
      "{'loss': 0.0068, 'learning_rate': 3.5431235431235434e-05, 'epoch': 0.87}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79deb576210f4be2815f88beab9e04a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00410860450938344, 'eval_recall': 0.0189873417721519, 'eval_precision': 0.15, 'eval_fbeta_score': 0.01964735516372796, 'eval_runtime': 156.7492, 'eval_samples_per_second': 8.108, 'eval_steps_per_second': 1.014, 'epoch': 1.0}\n",
      "{'loss': 0.0058, 'learning_rate': 3.251748251748252e-05, 'epoch': 1.05}\n",
      "{'loss': 0.0045, 'learning_rate': 2.9603729603729606e-05, 'epoch': 1.22}\n",
      "{'loss': 0.0061, 'learning_rate': 2.6689976689976692e-05, 'epoch': 1.4}\n",
      "{'loss': 0.0046, 'learning_rate': 2.377622377622378e-05, 'epoch': 1.57}\n",
      "{'loss': 0.0052, 'learning_rate': 2.0862470862470865e-05, 'epoch': 1.75}\n",
      "{'loss': 0.0052, 'learning_rate': 1.794871794871795e-05, 'epoch': 1.92}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be8b1a5fc4724bcbb25c714005291c05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.002976579125970602, 'eval_recall': 0.21835443037974683, 'eval_precision': 0.3791208791208791, 'eval_fbeta_score': 0.2219747587230883, 'eval_runtime': 151.8816, 'eval_samples_per_second': 8.368, 'eval_steps_per_second': 1.047, 'epoch': 2.0}\n",
      "{'loss': 0.0041, 'learning_rate': 1.5034965034965034e-05, 'epoch': 2.1}\n",
      "{'loss': 0.0053, 'learning_rate': 1.2121212121212122e-05, 'epoch': 2.27}\n",
      "{'loss': 0.0047, 'learning_rate': 9.207459207459208e-06, 'epoch': 2.45}\n",
      "{'loss': 0.0033, 'learning_rate': 6.2937062937062944e-06, 'epoch': 2.62}\n",
      "{'loss': 0.0038, 'learning_rate': 3.3799533799533803e-06, 'epoch': 2.8}\n",
      "{'loss': 0.0036, 'learning_rate': 4.662004662004662e-07, 'epoch': 2.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d15631cd08549ef91b6d3c75a8cff5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.002796303015202284, 'eval_recall': 0.26582278481012656, 'eval_precision': 0.3853211009174312, 'eval_fbeta_score': 0.2690317812269032, 'eval_runtime': 151.0298, 'eval_samples_per_second': 8.416, 'eval_steps_per_second': 1.053, 'epoch': 3.0}\n",
      "{'train_runtime': 5663.547, 'train_samples_per_second': 6.059, 'train_steps_per_second': 1.515, 'train_loss': 0.0418458515878046, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=8580, training_loss=0.0418458515878046, metrics={'train_runtime': 5663.547, 'train_samples_per_second': 6.059, 'train_steps_per_second': 1.515, 'train_loss': 0.0418458515878046, 'epoch': 3.0})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=CFG.training_args,\n",
    "    train_dataset=data_train,\n",
    "    eval_dataset=data_eval,\n",
    "    compute_metrics=partial(compute_metrics, labels_list=CFG.LABELS_LIST),\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0376ecb364424205b7a8ca9dca6b81ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/177 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.0026531913317739964,\n",
       " 'test_recall': 0.2755102040816326,\n",
       " 'test_precision': 0.48,\n",
       " 'test_fbeta_score': 0.2800997506234414,\n",
       " 'test_runtime': 178.1774,\n",
       " 'test_samples_per_second': 7.93,\n",
       " 'test_steps_per_second': 0.993,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(data_test, metric_key_prefix='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(CFG.model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_from_disk = AutoModelForTokenClassification.from_pretrained(CFG.model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86b139eadac1458581317b81c912c331",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/177 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.0008325826493091881,\n",
       " 'eval_recall': 0.8086734693877551,\n",
       " 'eval_precision': 0.8386243386243386,\n",
       " 'eval_fbeta_score': 0.8097858125368441,\n",
       " 'eval_runtime': 56.4552,\n",
       " 'eval_samples_per_second': 25.029,\n",
       " 'eval_steps_per_second': 3.135}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_from_huggingface = Trainer(\n",
    "    model=model_from_disk,\n",
    "    compute_metrics=partial(compute_metrics, labels_list=CFG.LABELS_LIST),\n",
    ")\n",
    "\n",
    "trainer_from_huggingface.evaluate(data_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
