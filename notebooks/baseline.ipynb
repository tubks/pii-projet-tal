{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook contains the currently working code for the baseline model. The final and ready-to-use version will be in src/baseline.py (at some point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, EarlyStoppingCallback, DataCollatorForTokenClassification, Trainer, TrainingArguments\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "from seqeval.metrics import recall_score, precision_score, accuracy_score\n",
    "from functools import partial\n",
    "\n",
    "# add the parent directory to the path so we can import the dataloader module\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from src.data.dataloader import preprocess_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'bert-base-uncased'\n",
    "TRAIN_HEAD_ONLY = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/zofia/Documents/UNI/UPARIS/sem2/pii-projet-tal/notebooks'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.abspath('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model configuration\n",
    "\n",
    "class CFG:\n",
    "    LABELS_LIST = ['B-NAME_STUDENT', 'B-EMAIL', 'B-USERNAME', 'B-ID_NUM', 'B-PHONE_NUM', 'B-URL_PERSONAL', 'B-STREET_ADDRESS', 'I-NAME_STUDENT', 'I-EMAIL', 'I-USERNAME', 'I-ID_NUM', 'I-PHONE_NUM','I-URL_PERSONAL','I-STREET_ADDRESS', 'O']\n",
    "    label2id = {label: i for i, label in enumerate(LABELS_LIST)}\n",
    "    label2id['[PAD]'] = -100\n",
    "    id2label = {i: label for label, i in label2id.items()}\n",
    "    seed = 42\n",
    "\n",
    "    # model checkpoint\n",
    "    model_name = 'bert-base-uncased'\n",
    "\n",
    "    # path to the directory where the model will be saved\n",
    "    local_path = os.path.abspath(os.path.abspath(''))\n",
    "    target_dir = os.path.join(local_path,'..','models', 'baseline')\n",
    "\n",
    "    #training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=os.path.join(target_dir, 'trainer'), \n",
    "        evaluation_strategy=\"epoch\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/zofia/Documents/UNI/UPARIS/sem2/pii-projet-tal/notebooks/../models/baseline'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CFG.target_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the model and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['document', 'full_text', 'tokens', 'trailing_whitespace', 'labels'],\n",
      "    num_rows: 6807\n",
      "})\n",
      "encoding the labels...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f01f8e9a3f1f4105a5e3674474ee13b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6807 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizing and aligning...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6048c17251bb47ab8072e8b89d4c5105",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6807 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flattening the data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:11<00:00,  1.99s/it]\n"
     ]
    }
   ],
   "source": [
    "data_path = os.path.join('..','data', 'raw', 'train.json')\n",
    "data = preprocess_data(data_path, tokenizer, CFG.label2id, keys_to_keep=['document'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['document', 'org_word_ids', 'attention_mask', 'token_type_ids', 'labels', 'input_ids'],\n",
       "    num_rows: 12812\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([-100, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 0, 0, 0, 7, 7, 14, 14, 14],\n",
       " '[CLS] design thinking for innovation reflexion - avril 2021 - nathalie sylla challenge & selection')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['labels'][0][:20], tokenizer.decode(data['input_ids'][0][:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_test = data.train_test_split(test_size=0.1, seed=CFG.seed)\n",
    "data_test = data_train_test['test']\n",
    "data_train_eval = data_train_test['train'].train_test_split(test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fbeta_score(precision, recall, beta=5.0):\n",
    "        b2 = beta ** 2\n",
    "        return (1 + b2) * ((precision * recall) / (b2 * precision + recall))\n",
    "\n",
    "def compute_metrics(p, labels_list):\n",
    "        predictions, labels = p\n",
    "        predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "        # Remove ignored index (special tokens)\n",
    "        true_predictions = [\n",
    "            [labels_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "            for prediction, label in zip(predictions, labels)\n",
    "        ]\n",
    "        true_labels = [\n",
    "            [labels_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "            for prediction, label in zip(predictions, labels)\n",
    "        ]\n",
    "\n",
    "        recall = recall_score(true_labels, true_predictions)\n",
    "        precision = precision_score(true_labels, true_predictions)\n",
    "        fbeta_score = get_fbeta_score(precision, recall)\n",
    "\n",
    "        results = {\n",
    "            'recall': recall,\n",
    "            'precision': precision,\n",
    "            'fbeta_score': fbeta_score\n",
    "            }\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    MODEL_NAME, num_labels=len(CFG.id2label), id2label=CFG.id2label, label2id=CFG.label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training all layers\n"
     ]
    }
   ],
   "source": [
    "#freezing the BERT layers\n",
    "if TRAIN_HEAD_ONLY:\n",
    "    print('Training head only')\n",
    "    for param in model.base_model.parameters():\n",
    "        param.requires_grad = False\n",
    "else:\n",
    "    print('Training all layers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/projet-en-tal/lib/python3.11/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a50430278614d0891f41b3a34dbe35d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3894 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory /Users/zofia/Documents/UNI/UPARIS/sem2/pii-projet-tal/notebooks/../models/baseline/trainer/checkpoint-500 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0243, 'learning_rate': 4.3579866461222396e-05, 'epoch': 0.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory /Users/zofia/Documents/UNI/UPARIS/sem2/pii-projet-tal/notebooks/../models/baseline/trainer/checkpoint-1000 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0035, 'learning_rate': 3.715973292244479e-05, 'epoch': 0.77}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27a404bce8b5475ca8853e99f44d9815",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/145 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0016380001325160265, 'eval_recall': 0.8444444444444444, 'eval_precision': 0.7139874739039666, 'eval_fbeta_score': 0.8385514900037722, 'eval_runtime': 48.5972, 'eval_samples_per_second': 23.726, 'eval_steps_per_second': 2.984, 'epoch': 1.0}\n",
      "{'loss': 0.0025, 'learning_rate': 3.073959938366718e-05, 'epoch': 1.16}\n",
      "{'loss': 0.0013, 'learning_rate': 2.4319465844889575e-05, 'epoch': 1.54}\n",
      "{'loss': 0.0012, 'learning_rate': 1.789933230611197e-05, 'epoch': 1.93}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5b12de7685d4b34ace2ef6fa6ee8918",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/145 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0010410952381789684, 'eval_recall': 0.8864197530864197, 'eval_precision': 0.8466981132075472, 'eval_fbeta_score': 0.8848232059910892, 'eval_runtime': 45.4898, 'eval_samples_per_second': 25.346, 'eval_steps_per_second': 3.188, 'epoch': 2.0}\n",
      "{'loss': 0.0007, 'learning_rate': 1.147919876733436e-05, 'epoch': 2.31}\n",
      "{'loss': 0.0004, 'learning_rate': 5.059065228556755e-06, 'epoch': 2.7}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e3d4733a69c429aa0e26011e4be89d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/145 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0010464797960594296, 'eval_recall': 0.9061728395061729, 'eval_precision': 0.8615023474178404, 'eval_fbeta_score': 0.9043692540991376, 'eval_runtime': 44.4972, 'eval_samples_per_second': 25.912, 'eval_steps_per_second': 3.259, 'epoch': 3.0}\n",
      "{'train_runtime': 4385.6561, 'train_samples_per_second': 7.098, 'train_steps_per_second': 0.888, 'train_loss': 0.004421819466380015, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3894, training_loss=0.004421819466380015, metrics={'train_runtime': 4385.6561, 'train_samples_per_second': 7.098, 'train_steps_per_second': 0.888, 'train_loss': 0.004421819466380015, 'epoch': 3.0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=CFG.training_args,\n",
    "    train_dataset=data_train_eval[\"train\"],\n",
    "    eval_dataset=data_train_eval[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=partial(compute_metrics, labels_list=CFG.LABELS_LIST),\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = os.path.join(CFG.target_dir, 'model')\n",
    "trainer.save_model(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "265c8af91d19459a8870afacf48b3420",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/zmilczarek/pii-detection-baseline-v0.2/commit/69813013ed2ebe1117333b9d8b8a1fbe2e85cf93', commit_message='Upload BertForTokenClassification', commit_description='', oid='69813013ed2ebe1117333b9d8b8a1fbe2e85cf93', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = AutoModelForTokenClassification.from_pretrained(model_save_path)\n",
    "# token = [put your token here]\n",
    "# model.push_to_hub('zmilczarek/pii-detection-baseline-v0.2', token = token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to('cpu')\n",
    "with torch.no_grad():\n",
    "    p = model(torch.tensor(data['input_ids'][:10]), return_dict=True)\n",
    "    p = (p.logits, torch.tensor(data['labels'][:10]))\n",
    "    r = compute_metrics(p, CFG.LABELS_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recall': 0.9411764705882353,\n",
       " 'precision': 0.8888888888888888,\n",
       " 'fbeta_score': 0.9390519187358916}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/projet-en-tal/lib/python3.11/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "413147777d404935ab0f99e4de5311ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/161 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.0023406886029988527,\n",
       " 'eval_recall': 0.7954070981210856,\n",
       " 'eval_precision': 0.8141025641025641,\n",
       " 'eval_fbeta_score': 0.7961102627983605,\n",
       " 'eval_runtime': 50.3979,\n",
       " 'eval_samples_per_second': 25.438,\n",
       " 'eval_steps_per_second': 3.195}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_dataset=data_train_eval[\"train\"],\n",
    "    eval_dataset=data_test,\n",
    "    compute_metrics=partial(compute_metrics, labels_list = CFG.LABELS_LIST),\n",
    ")\n",
    "\n",
    "#eval\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_just_tags(p, labels_list):\n",
    "        predictions, labels = p\n",
    "        predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "        # Remove ignored index (special tokens)\n",
    "        true_predictions = [\n",
    "            [labels_list[p] for (p, l) in zip(prediction, label) if l != -100 and labels_list[l] != 'O']\n",
    "            for prediction, label in zip(predictions, labels)\n",
    "        ]\n",
    "        true_labels = [\n",
    "            [labels_list[l] for (p, l) in zip(prediction, label) if l != -100 and labels_list[l] != 'O']\n",
    "            for prediction, label in zip(predictions, labels)\n",
    "        ]\n",
    "\n",
    "        recall = recall_score(true_labels, true_predictions)\n",
    "        precision = precision_score(true_labels, true_predictions)\n",
    "        fbeta_score = get_fbeta_score(precision, recall)\n",
    "        accuracy = accuracy_score(true_labels, true_predictions)\n",
    "\n",
    "        results = {\n",
    "            'recall': recall,\n",
    "            'precision': precision,\n",
    "            'fbeta_score': fbeta_score,\n",
    "            'accuracy': accuracy\n",
    "            }\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ed10c159a44493996658ed4d536433d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/161 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.0023406886029988527,\n",
       " 'eval_recall': 0.7974947807933194,\n",
       " 'eval_precision': 0.9769820971867008,\n",
       " 'eval_fbeta_score': 0.8031699822092835,\n",
       " 'eval_accuracy': 0.801980198019802,\n",
       " 'eval_runtime': 48.6449,\n",
       " 'eval_samples_per_second': 26.354,\n",
       " 'eval_steps_per_second': 3.31}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_dataset=data_train_eval[\"train\"],\n",
    "    eval_dataset=data_test,\n",
    "    compute_metrics=partial(compute_metrics_just_tags, labels_list = CFG.LABELS_LIST),\n",
    ")\n",
    "\n",
    "#eval\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = 'model/model_initial_preprocessing'\n",
    "model_loaded = AutoModelForTokenClassification.from_pretrained(model_dir)\n",
    "model_loaded = model_loaded.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_from_huggingface = AutoModelForTokenClassification.from_pretrained('zmilczarek/pii-detection-baseline-v0.2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data_split = data.train_test_split(test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask', 'org_word_ids', 'document'],\n",
       "    num_rows: 5474\n",
       "})"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d6c6d5f730942458dcc87d650ce41b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/161 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.000548205862287432,\n",
       " 'eval_recall': 0.964509394572025,\n",
       " 'eval_precision': 0.9506172839506173,\n",
       " 'eval_fbeta_score': 0.9639675788459995,\n",
       " 'eval_accuracy': 0.9519094766619519,\n",
       " 'eval_runtime': 50.3617,\n",
       " 'eval_samples_per_second': 25.456,\n",
       " 'eval_steps_per_second': 3.197}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model_from_huggingface,\n",
    "    train_dataset=data_train_eval[\"train\"],\n",
    "    eval_dataset=data_test,\n",
    "    compute_metrics=partial(compute_metrics_just_tags, labels_list = CFG.LABELS_LIST),\n",
    ")\n",
    "\n",
    "#eval\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The plan to make the model label test.csv correctly\n",
    "\n",
    "1. Load the model\n",
    "2. Prepare the dataset  (prepare input ids/ att mask in chunks)\n",
    "3. Get the labels\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projet-en-tal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
