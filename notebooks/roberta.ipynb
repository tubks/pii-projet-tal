{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from datasets import Dataset\n",
    "from functools import reduce\n",
    "from seqeval.metrics import recall_score, precision_score\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "from functools import partial\n",
    "\n",
    "# add the parent directory to the path so we can import the dataloader module\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from src.data.dataloader import preprocess_data, get_dataset_from_path, get_train_val_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "current versions:\n",
    "- zmilczarek/pii-detection-roberta-v3\n",
    "- zmilczarek/pii-detection-roberta-v2\n",
    "- zeinab-sheikhi/Roberta-pii-detection-baseline (not trained on the unified data split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Roberta\n",
    " The inputs of the model take pieces of 512 contiguous tokens that may span over documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline roberta model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training below produced roberta-v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    LABELS_LIST = ['B-NAME_STUDENT', 'B-EMAIL', 'B-USERNAME', 'B-ID_NUM', 'B-PHONE_NUM', 'B-URL_PERSONAL', 'B-STREET_ADDRESS', 'I-NAME_STUDENT', 'I-EMAIL', 'I-USERNAME', 'I-ID_NUM', 'I-PHONE_NUM','I-URL_PERSONAL','I-STREET_ADDRESS', 'O']\n",
    "    label2id = {label: i for i, label in enumerate(LABELS_LIST)}\n",
    "    label2id['[PAD]'] = -100\n",
    "    id2label = {i: label for label, i in label2id.items()}\n",
    "    seed = 42\n",
    "\n",
    "    # model checkpoint\n",
    "    model_name = 'roberta-base'\n",
    "    train_head_only = False\n",
    "\n",
    "    # path to the directory where the model will be saved\n",
    "    local_path = os.path.abspath(os.path.abspath(''))\n",
    "    target_dir = os.path.join(local_path,'..','models', 'roberta-base-experiment')\n",
    "\n",
    "    #training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=os.path.join(target_dir, 'trainer'), \n",
    "        evaluation_strategy=\"epoch\"\n",
    "        )\n",
    "    model_save_path = os.path.join(target_dir, 'model')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(CFG.model_name, add_prefix_space=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoding the labels...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23bf14ea65bc49ddaddda33979dd5690",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6807 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizing and aligning...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebf08606bd3548c09cfdcfcedeecb36b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6807 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flattening the data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:06<00:00,  1.11s/it]\n"
     ]
    }
   ],
   "source": [
    "keys_to_flatten = ['labels', 'input_ids', 'attention_mask', 'org_word_ids','document']\n",
    "data_path = os.path.join('..','data', 'raw', 'train.json')\n",
    "data = get_dataset_from_path(data_path)\n",
    "data = preprocess_data(data, tokenizer, label2id = CFG.label2id, keys_to_flatten=keys_to_flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_eval, data_test = get_train_val_test_split(data, seed=CFG.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fbeta_score(precision, recall, beta=5.0):\n",
    "        b2 = beta ** 2\n",
    "        return (1 + b2) * ((precision * recall) / (b2 * precision + recall))\n",
    "\n",
    "def compute_metrics(p, labels_list):\n",
    "        predictions, labels = p\n",
    "        predictions = np.argmax(predictions, axis=2)\n",
    "        preds_set = np.unique(predictions)\n",
    "\n",
    "        for pred in preds_set:\n",
    "            assert pred in list(range(len(labels_list))) and pred !=-100, f\"Predicted label {pred} is not in the labels list \\npreds_set: {preds_set}\"\n",
    "        # Remove ignored index (special tokens)\n",
    "        \n",
    "        true_predictions = [\n",
    "            [labels_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "            for prediction, label in zip(predictions, labels)\n",
    "        ]\n",
    "        true_labels = [\n",
    "            [labels_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "            for prediction, label in zip(predictions, labels)\n",
    "        ]\n",
    "\n",
    "        recall = recall_score(true_labels, true_predictions)\n",
    "        precision = precision_score(true_labels, true_predictions)\n",
    "        fbeta_score = get_fbeta_score(precision, recall)\n",
    "\n",
    "        results = {\n",
    "            'recall': recall,\n",
    "            'precision': precision,\n",
    "            'fbeta_score': fbeta_score\n",
    "            }\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    CFG.model_name, num_labels=len(CFG.id2label), id2label=CFG.id2label, label2id=CFG.label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/projet-en-tal/lib/python3.11/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=CFG.training_args,\n",
    "    train_dataset=data_train,\n",
    "    eval_dataset=data_eval,\n",
    "    compute_metrics=partial(compute_metrics, labels_list=CFG.LABELS_LIST),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d424fa2ba8d04652945f422fcec4d7f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4290 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6a3159b546a4ecbaafd19bf7b3987fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0008855126798152924, 'eval_recall': 0.9208860759493671, 'eval_precision': 0.7385786802030457, 'eval_fbeta_score': 0.9122257053291535, 'eval_runtime': 51.961, 'eval_samples_per_second': 24.461, 'eval_steps_per_second': 3.06, 'epoch': 3.0}\n",
      "{'train_runtime': 369.1821, 'train_samples_per_second': 92.954, 'train_steps_per_second': 11.62, 'train_loss': 2.4982217030647474e-05, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4290, training_loss=2.4982217030647474e-05, metrics={'train_runtime': 369.1821, 'train_samples_per_second': 92.954, 'train_steps_per_second': 11.62, 'train_loss': 2.4982217030647474e-05, 'epoch': 3.0})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train(resume_from_checkpoint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5460458434f4d57a2d7e87a2b196285",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/177 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.0009286311105825007,\n",
       " 'test_recall': 0.9132653061224489,\n",
       " 'test_precision': 0.7991071428571429,\n",
       " 'test_fbeta_score': 0.9082747853239658,\n",
       " 'test_runtime': 55.9538,\n",
       " 'test_samples_per_second': 25.253,\n",
       " 'test_steps_per_second': 3.163,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(data_test, metric_key_prefix='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(CFG.model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the above is saved in the 'experiment' folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_to_push = AutoModelForTokenClassification.from_pretrained(CFG.model_save_path)\n",
    "# token = 'token_here'\n",
    "# model_to_push.push_to_hub('zmilczarek/pii-detection-roberta-v3', token=token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d0e8708effa43bf8d9a5f4654dba712",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abd3fbbfcb9c4458a60e2cd79460d015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/496M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_from_huggingface = AutoModelForTokenClassification.from_pretrained('zmilczarek/pii-detection-roberta-v3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ad70c8b418348a4aa2835e91b9282dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/177 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.0008325826493091881,\n",
       " 'eval_recall': 0.8086734693877551,\n",
       " 'eval_precision': 0.8386243386243386,\n",
       " 'eval_fbeta_score': 0.8097858125368441,\n",
       " 'eval_runtime': 56.0802,\n",
       " 'eval_samples_per_second': 25.196,\n",
       " 'eval_steps_per_second': 3.156}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_from_huggingface = Trainer(\n",
    "    model=model_from_huggingface,\n",
    "    compute_metrics=partial(compute_metrics, labels_list=CFG.LABELS_LIST),\n",
    ")\n",
    "\n",
    "trainer_from_huggingface.evaluate(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roberta - finetuning just the HEAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG_just_head:\n",
    "    LABELS_LIST = ['B-NAME_STUDENT', 'B-EMAIL', 'B-USERNAME', 'B-ID_NUM', 'B-PHONE_NUM', 'B-URL_PERSONAL', 'B-STREET_ADDRESS', 'I-NAME_STUDENT', 'I-EMAIL', 'I-USERNAME', 'I-ID_NUM', 'I-PHONE_NUM','I-URL_PERSONAL','I-STREET_ADDRESS', 'O']\n",
    "    label2id = {label: i for i, label in enumerate(LABELS_LIST)}\n",
    "    label2id['[PAD]'] = -100\n",
    "    id2label = {i: label for label, i in label2id.items()}\n",
    "    seed = 42\n",
    "\n",
    "    # model checkpoint\n",
    "    model_name = 'roberta-base'\n",
    "    train_head_only = True\n",
    "\n",
    "    # path to the directory where the model will be saved\n",
    "    local_path = os.path.abspath(os.path.abspath(''))\n",
    "    target_dir = os.path.join(local_path,'..','models', 'roberta-base')\n",
    "\n",
    "    #training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=os.path.join(target_dir, 'trainer_just_head'), \n",
    "        evaluation_strategy=\"epoch\",\n",
    "        num_train_epochs=10,\n",
    "        learning_rate=1e-5)\n",
    "    model_save_path = os.path.join(target_dir, 'model_just_head')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training head only\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    CFG_just_head.model_name, num_labels=len(CFG_just_head.id2label), id2label=CFG_just_head.id2label, label2id=CFG_just_head.label2id\n",
    ")\n",
    "for param in model.base_model.parameters():\n",
    "        param.requires_grad = False\n",
    "print('\\nTraining head only')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_head_only = Trainer(\n",
    "    model=model,\n",
    "    args=CFG_just_head.training_args,\n",
    "    train_dataset=data_train,\n",
    "    eval_dataset=data_eval,\n",
    "    compute_metrics=partial(compute_metrics, labels_list=CFG_just_head.LABELS_LIST),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "current problem : compute metrics crashes and the model wants to train for 38hrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aa19bbb4aff4211a922968f09fec6ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1446, 'learning_rate': 9.650349650349651e-06, 'epoch': 0.35}\n",
      "{'loss': 1.5924, 'learning_rate': 9.300699300699301e-06, 'epoch': 0.7}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11dbcc395b07414cb9632de86a2d48c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/projet-en-tal/lib/python3.11/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/var/folders/m7/vrkpy5hd5n13p506z3dk5yg40000gn/T/ipykernel_69728/3547565051.py:3: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return (1 + b2) * ((precision * recall) / (b2 * precision + recall))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0211737155914307, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_fbeta_score': nan, 'eval_runtime': 48.0388, 'eval_samples_per_second': 26.458, 'eval_steps_per_second': 3.31, 'epoch': 1.0}\n",
      "{'loss': 1.1538, 'learning_rate': 8.951048951048951e-06, 'epoch': 1.05}\n",
      "{'loss': 0.8266, 'learning_rate': 8.601398601398602e-06, 'epoch': 1.4}\n",
      "{'loss': 0.5889, 'learning_rate': 8.251748251748254e-06, 'epoch': 1.75}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b3b9925c80f480eb57d985ef4be1820",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/projet-en-tal/lib/python3.11/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/var/folders/m7/vrkpy5hd5n13p506z3dk5yg40000gn/T/ipykernel_69728/3547565051.py:3: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return (1 + b2) * ((precision * recall) / (b2 * precision + recall))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.36827197670936584, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_fbeta_score': nan, 'eval_runtime': 47.6737, 'eval_samples_per_second': 26.66, 'eval_steps_per_second': 3.335, 'epoch': 2.0}\n",
      "{'loss': 0.4204, 'learning_rate': 7.902097902097902e-06, 'epoch': 2.1}\n",
      "{'loss': 0.3039, 'learning_rate': 7.552447552447552e-06, 'epoch': 2.45}\n",
      "{'loss': 0.2163, 'learning_rate': 7.202797202797203e-06, 'epoch': 2.8}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0d85a6d21bc4371b3c9b85f8bfa1f65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/projet-en-tal/lib/python3.11/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/var/folders/m7/vrkpy5hd5n13p506z3dk5yg40000gn/T/ipykernel_69728/3547565051.py:3: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return (1 + b2) * ((precision * recall) / (b2 * precision + recall))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.13764449954032898, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_fbeta_score': nan, 'eval_runtime': 47.6876, 'eval_samples_per_second': 26.653, 'eval_steps_per_second': 3.334, 'epoch': 3.0}\n",
      "{'loss': 0.1617, 'learning_rate': 6.853146853146854e-06, 'epoch': 3.15}\n",
      "{'loss': 0.1205, 'learning_rate': 6.503496503496504e-06, 'epoch': 3.5}\n",
      "{'loss': 0.0954, 'learning_rate': 6.153846153846155e-06, 'epoch': 3.85}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c18275c02a1740fda401e813af6d1ad2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/projet-en-tal/lib/python3.11/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/var/folders/m7/vrkpy5hd5n13p506z3dk5yg40000gn/T/ipykernel_69728/3547565051.py:3: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return (1 + b2) * ((precision * recall) / (b2 * precision + recall))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06435351818799973, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_fbeta_score': nan, 'eval_runtime': 47.714, 'eval_samples_per_second': 26.638, 'eval_steps_per_second': 3.332, 'epoch': 4.0}\n",
      "{'loss': 0.0778, 'learning_rate': 5.804195804195804e-06, 'epoch': 4.2}\n",
      "{'loss': 0.0664, 'learning_rate': 5.4545454545454545e-06, 'epoch': 4.55}\n",
      "{'loss': 0.0584, 'learning_rate': 5.1048951048951055e-06, 'epoch': 4.9}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6053bcb10eb414f87c590f269e9cad6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/projet-en-tal/lib/python3.11/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/var/folders/m7/vrkpy5hd5n13p506z3dk5yg40000gn/T/ipykernel_69728/3547565051.py:3: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return (1 + b2) * ((precision * recall) / (b2 * precision + recall))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.04016344994306564, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_fbeta_score': nan, 'eval_runtime': 46.3613, 'eval_samples_per_second': 27.415, 'eval_steps_per_second': 3.43, 'epoch': 5.0}\n",
      "{'loss': 0.0503, 'learning_rate': 4.755244755244756e-06, 'epoch': 5.24}\n",
      "{'loss': 0.0463, 'learning_rate': 4.405594405594406e-06, 'epoch': 5.59}\n",
      "{'loss': 0.0403, 'learning_rate': 4.055944055944056e-06, 'epoch': 5.94}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02f3cceb38a641dfa963a0976e85a40c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/projet-en-tal/lib/python3.11/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/var/folders/m7/vrkpy5hd5n13p506z3dk5yg40000gn/T/ipykernel_69728/3547565051.py:3: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return (1 + b2) * ((precision * recall) / (b2 * precision + recall))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.02843858301639557, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_fbeta_score': nan, 'eval_runtime': 46.3029, 'eval_samples_per_second': 27.45, 'eval_steps_per_second': 3.434, 'epoch': 6.0}\n",
      "{'loss': 0.0371, 'learning_rate': 3.7062937062937064e-06, 'epoch': 6.29}\n",
      "{'loss': 0.0339, 'learning_rate': 3.356643356643357e-06, 'epoch': 6.64}\n",
      "{'loss': 0.0324, 'learning_rate': 3.006993006993007e-06, 'epoch': 6.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "558edaad82c046b2900620be6cc2e507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/projet-en-tal/lib/python3.11/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/var/folders/m7/vrkpy5hd5n13p506z3dk5yg40000gn/T/ipykernel_69728/3547565051.py:3: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return (1 + b2) * ((precision * recall) / (b2 * precision + recall))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.022022198885679245, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_fbeta_score': nan, 'eval_runtime': 46.3236, 'eval_samples_per_second': 27.437, 'eval_steps_per_second': 3.432, 'epoch': 7.0}\n",
      "{'loss': 0.0306, 'learning_rate': 2.6573426573426574e-06, 'epoch': 7.34}\n",
      "{'loss': 0.029, 'learning_rate': 2.307692307692308e-06, 'epoch': 7.69}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ec717394db946fca66bfc926f1c1937",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/projet-en-tal/lib/python3.11/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/var/folders/m7/vrkpy5hd5n13p506z3dk5yg40000gn/T/ipykernel_69728/3547565051.py:3: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return (1 + b2) * ((precision * recall) / (b2 * precision + recall))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.018407242372632027, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_fbeta_score': nan, 'eval_runtime': 46.298, 'eval_samples_per_second': 27.453, 'eval_steps_per_second': 3.434, 'epoch': 8.0}\n",
      "{'loss': 0.0258, 'learning_rate': 1.9580419580419583e-06, 'epoch': 8.04}\n",
      "{'loss': 0.0264, 'learning_rate': 1.6083916083916085e-06, 'epoch': 8.39}\n",
      "{'loss': 0.0246, 'learning_rate': 1.258741258741259e-06, 'epoch': 8.74}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1469cd7b793447a99f23548239e919ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/projet-en-tal/lib/python3.11/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/var/folders/m7/vrkpy5hd5n13p506z3dk5yg40000gn/T/ipykernel_69728/3547565051.py:3: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return (1 + b2) * ((precision * recall) / (b2 * precision + recall))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.016538305208086967, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_fbeta_score': nan, 'eval_runtime': 46.2815, 'eval_samples_per_second': 27.462, 'eval_steps_per_second': 3.435, 'epoch': 9.0}\n",
      "{'loss': 0.0242, 'learning_rate': 9.090909090909091e-07, 'epoch': 9.09}\n",
      "{'loss': 0.0241, 'learning_rate': 5.594405594405595e-07, 'epoch': 9.44}\n",
      "{'loss': 0.0231, 'learning_rate': 2.097902097902098e-07, 'epoch': 9.79}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "188d9ce8e6474e60998bc027acb0c03f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.01594206690788269, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_fbeta_score': nan, 'eval_runtime': 46.2887, 'eval_samples_per_second': 27.458, 'eval_steps_per_second': 3.435, 'epoch': 10.0}\n",
      "{'train_runtime': 5808.5798, 'train_samples_per_second': 19.693, 'train_steps_per_second': 2.462, 'train_loss': 0.28984168146040057, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/projet-en-tal/lib/python3.11/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/var/folders/m7/vrkpy5hd5n13p506z3dk5yg40000gn/T/ipykernel_69728/3547565051.py:3: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return (1 + b2) * ((precision * recall) / (b2 * precision + recall))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=14300, training_loss=0.28984168146040057, metrics={'train_runtime': 5808.5798, 'train_samples_per_second': 19.693, 'train_steps_per_second': 2.462, 'train_loss': 0.28984168146040057, 'epoch': 10.0})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_head_only.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_head_only.save_model(CFG_just_head.model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ae06b38835548c391b2a02cadad3042",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/177 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m7/vrkpy5hd5n13p506z3dk5yg40000gn/T/ipykernel_69728/3547565051.py:3: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return (1 + b2) * ((precision * recall) / (b2 * precision + recall))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.0167564507573843,\n",
       " 'test_recall': 0.0,\n",
       " 'test_precision': 0.0,\n",
       " 'test_fbeta_score': nan,\n",
       " 'test_runtime': 51.5318,\n",
       " 'test_samples_per_second': 27.42,\n",
       " 'test_steps_per_second': 3.435,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_head_only.evaluate(data_test, metric_key_prefix='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Roberta : The model doesn't learn with these hyperparameters and on head only"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
