{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using roberta with synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "import os\n",
    "import numpy as np\n",
    "from seqeval.metrics import recall_score, precision_score, accuracy_score\n",
    "from functools import partial\n",
    "from datasets import concatenate_datasets\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from src.data.dataloader import preprocess_data, get_dataset_from_path, get_train_val_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    LABELS_LIST = ['B-NAME_STUDENT', 'B-EMAIL', 'B-USERNAME', 'B-ID_NUM', 'B-PHONE_NUM', 'B-URL_PERSONAL', 'B-STREET_ADDRESS', 'I-NAME_STUDENT', 'I-EMAIL', 'I-USERNAME', 'I-ID_NUM', 'I-PHONE_NUM','I-URL_PERSONAL','I-STREET_ADDRESS', 'O']\n",
    "    label2id = {label: i for i, label in enumerate(LABELS_LIST)}\n",
    "    label2id['[PAD]'] = -100\n",
    "    id2label = {i: label for label, i in label2id.items()}\n",
    "    seed = 42\n",
    "\n",
    "    # model checkpoint\n",
    "    model_name = 'roberta-base'\n",
    "\n",
    "    #path to the training data\n",
    "    train_data_path = os.path.join('..','data', 'raw', 'synthetic', 'mixtral.json')\n",
    "    \n",
    "    # path to the directory where the model will be saved\n",
    "    local_path = os.path.abspath(os.path.abspath(''))\n",
    "    target_dir = os.path.join(local_path,'..','models', 'mixtral_roberta')\n",
    "\n",
    "    #training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=os.path.join(target_dir, 'trainer'), \n",
    "        evaluation_strategy=\"epoch\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(CFG.model_name, add_prefix_space=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoding the labels...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "953166743410437e9aabb4771a32713c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2355 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizing and aligning...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a29b94acfeca4ebea17bddafecab422a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2355 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flattening the data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:03<00:00,  1.27it/s]\n"
     ]
    }
   ],
   "source": [
    "data = get_dataset_from_path(CFG.train_data_path)\n",
    "keys_to_flatten = ['input_ids', 'attention_mask', 'org_word_ids', 'document']\n",
    "data = preprocess_data(data, tokenizer, label2id = CFG.label2id, keys_to_flatten=keys_to_flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<s> Rose - Mai Rodriguez | PIN # 3814374 \\n 501 Andrea Highway \\n North Tara, MP 38342 | rose-mairodriguez@comcast.net \\n\\n Introduction - Identifying the Challenge : \\n\\n As a User Experience Designer at a tech company, I am frequently confronted with complex challenges related to designing user - friendly interfaces that meet the needs and expectations of our diverse user base. One such challenge that I recently encountered was how to redesign our company's mobile app to better accommodate the needs of our aging user population. This challenge was significant and complex because older adults often have unique needs and abilities that are not typically considered in mainstream design practices. Additionally, this population has been historically underserved in the tech industry, making it even more critical to address their needs effectively. \\n\\n Selection of the Tool or Approach : \\n\\n To address this challenge, I chose to apply the User - Centered Design ( UCD ) approach, which is a well - established and widely used methodology for designing user - friendly interfaces. I selected this method because it emphasizes the importance of understanding user needs and involves users in the design process from the beginning, making it well - suited for designing products for populations with unique needs and abilities. Furthermore, UCD is a iterative process that allows for continuous feedback and improvement, making it a flexible and adaptable methodology. \\n\\n I also considered alternatives such as heuristic evaluation and usability testing, but discarded them in favor of UCD because these methods tend to focus on identifying and fixing usability issues, rather than understanding and addressing the underlying user needs. \\n\\n Application of the Tool or Approach : \\n\\n To apply UCD to the mobile app redesign, I followed a series of specific steps and processes. First, I conducted user research to understand the needs, abilities, and preferences of our aging user population. This involved conducting interviews, surveys, and focus groups with older adults to gather data on their experiences using the existing mobile app, as well as their overall technology use and preferences. \\n\\n Next, I used the data from the user research to create personas, which are fictional representations of typical users, that captured the key characteristics and needs of our aging user population. I then used these personas to inform the design of wireframes, which are low - fidelity ( http://rodriguez.pets/explore-portfolio/video/about-work/about-photos )  visual representations of the proposed app interface. \\n\\n After creating the wireframes, I</s>\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(data['input_ids'][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_eval, data_test = get_train_val_test_split(data, seed=CFG.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fbeta_score(precision, recall, beta=5.0):\n",
    "        b2 = beta ** 2\n",
    "        return (1 + b2) * ((precision * recall) / (b2 * precision + recall))\n",
    "\n",
    "def compute_metrics(p, labels_list):\n",
    "        predictions, labels = p\n",
    "        predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "        # Remove ignored index (special tokens)\n",
    "        true_predictions = [\n",
    "            [labels_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "            for prediction, label in zip(predictions, labels)\n",
    "        ]\n",
    "        true_labels = [\n",
    "            [labels_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "            for prediction, label in zip(predictions, labels)\n",
    "        ]\n",
    "\n",
    "        recall = recall_score(true_labels, true_predictions)\n",
    "        precision = precision_score(true_labels, true_predictions)\n",
    "        fbeta_score = get_fbeta_score(precision, recall)\n",
    "\n",
    "        results = {\n",
    "            'recall': recall,\n",
    "            'precision': precision,\n",
    "            'fbeta_score': fbeta_score\n",
    "            }\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    CFG.model_name, num_labels=len(CFG.id2label), id2label=CFG.id2label, label2id=CFG.label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/projet-en-tal/lib/python3.11/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06f330370b9346229cb1d16fa3e40016",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1707 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory /Users/zofia/Documents/UNI/UPARIS/sem2/pii-projet-tal/notebooks/../models/mixtral_roberta/trainer/checkpoint-500 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0318, 'learning_rate': 3.5354422964264796e-05, 'epoch': 0.88}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a46753ef99c4446b0456099dcb9c54b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0008873186889104545, 'eval_recall': 0.9960274108650313, 'eval_precision': 0.997612652939421, 'eval_fbeta_score': 0.9960882885498399, 'eval_runtime': 19.8372, 'eval_samples_per_second': 25.457, 'eval_steps_per_second': 3.226, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory /Users/zofia/Documents/UNI/UPARIS/sem2/pii-projet-tal/notebooks/../models/mixtral_roberta/trainer/checkpoint-1000 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0006, 'learning_rate': 2.0708845928529586e-05, 'epoch': 1.76}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b76d913941af4ebf92f2862b36418c07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00047899619676172733, 'eval_recall': 0.9972191876055219, 'eval_precision': 0.9985083532219571, 'eval_fbeta_score': 0.997268709341014, 'eval_runtime': 19.0672, 'eval_samples_per_second': 26.485, 'eval_steps_per_second': 3.357, 'epoch': 2.0}\n",
      "{'loss': 0.0003, 'learning_rate': 6.0632688927943766e-06, 'epoch': 2.64}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d58843f789254d50a9f30b77b92c95a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0002759890630841255, 'eval_recall': 0.9990068527162578, 'eval_precision': 0.9987092930897538, 'eval_fbeta_score': 0.9989954048365718, 'eval_runtime': 19.1475, 'eval_samples_per_second': 26.374, 'eval_steps_per_second': 3.342, 'epoch': 3.0}\n",
      "{'train_runtime': 1889.1764, 'train_samples_per_second': 7.217, 'train_steps_per_second': 0.904, 'train_loss': 0.009629794311893565, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1707, training_loss=0.009629794311893565, metrics={'train_runtime': 1889.1764, 'train_samples_per_second': 7.217, 'train_steps_per_second': 0.904, 'train_loss': 0.009629794311893565, 'epoch': 3.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=CFG.training_args,\n",
    "    train_dataset=data_train,\n",
    "    eval_dataset=data_eval,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=partial(compute_metrics, labels_list=CFG.LABELS_LIST),\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = os.path.join(CFG.target_dir, 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/projet-en-tal/lib/python3.11/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "522eaf38df7245af82bcd8ab9709a36a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.0007727962802164257,\n",
       " 'eval_recall': 0.998916756936922,\n",
       " 'eval_precision': 0.9985839233652645,\n",
       " 'eval_fbeta_score': 0.9989039515431208,\n",
       " 'eval_runtime': 23.2797,\n",
       " 'eval_samples_per_second': 24.141,\n",
       " 'eval_steps_per_second': 3.05}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    eval_dataset=data_test,\n",
    "    compute_metrics=partial(compute_metrics, labels_list = CFG.LABELS_LIST),\n",
    ")\n",
    "\n",
    "#eval\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating on train.json (original dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoding the labels...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05e3fba30eba4797a5cc8bd6663b88af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6807 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizing and aligning...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e307945fe8fa479985a272e89dc0a9fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6807 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flattening the data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:13<00:00,  2.18s/it]\n"
     ]
    }
   ],
   "source": [
    "kaggle_data_path = os.path.join('..','data', 'raw', 'train.json')\n",
    "kaggle_data = get_dataset_from_path(kaggle_data_path)\n",
    "kaggle_data = preprocess_data(kaggle_data, tokenizer, label2id = CFG.label2id, keys_to_flatten=keys_to_flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_train, kaggle_val, kaggle_test = get_train_val_test_split(kaggle_data, seed=CFG.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating on the standard test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c34e4734ba54a6b8a864e1fd48b83ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/177 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.01543649286031723,\n",
       " 'eval_recall': 0.7372448979591837,\n",
       " 'eval_precision': 0.25643300798580304,\n",
       " 'eval_fbeta_score': 0.6876544339708976,\n",
       " 'eval_runtime': 54.6587,\n",
       " 'eval_samples_per_second': 25.851,\n",
       " 'eval_steps_per_second': 3.238}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(kaggle_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating on the whole original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3428c261acc44f2a9b5ed0cbbdfc099",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1766 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.015895720571279526,\n",
       " 'eval_recall': 0.7844444444444445,\n",
       " 'eval_precision': 0.31398075523570795,\n",
       " 'eval_fbeta_score': 0.7417001550137016,\n",
       " 'eval_runtime': 612.0197,\n",
       " 'eval_samples_per_second': 23.076,\n",
       " 'eval_steps_per_second': 2.886}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(kaggle_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining both datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fc921c2911649c981cfc1dbc8c907cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14123 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kaggle_data = kaggle_data.map(lambda examples: {'document1': str(examples['document'])}, remove_columns=['document'])\n",
    "kaggle_data = kaggle_data.rename_column('document1', 'document')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_train, kaggle_val, kaggle_test = get_train_val_test_split(kaggle_data, seed=CFG.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None),\n",
       " 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None),\n",
       " 'org_word_ids': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None),\n",
       " 'document': Value(dtype='string', id=None),\n",
       " 'labels': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'org_word_ids', 'document', 'labels'],\n",
       "    num_rows: 1975\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_train_data = concatenate_datasets([data_train, kaggle_train])\n",
    "combined_train_data.shuffle()\n",
    "combined_val_data = concatenate_datasets([data_eval, kaggle_val])\n",
    "combined_val_data.shuffle()\n",
    "combined_test_data = concatenate_datasets([data_test, kaggle_test])\n",
    "combined_test_data.shuffle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model on comined data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/homebrew/anaconda3/envs/projet-en-tal/lib/python3.11/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccc0a9a5a642484b8aa961679ca58a9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5994 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0232, 'learning_rate': 4.582916249582916e-05, 'epoch': 0.25}\n",
      "{'loss': 0.0038, 'learning_rate': 4.165832499165833e-05, 'epoch': 0.5}\n",
      "{'loss': 0.0022, 'learning_rate': 3.7487487487487486e-05, 'epoch': 0.75}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7574e2a1ed2948eb8f81f773564b3adb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0012952466495335102, 'eval_recall': 0.9850746268656716, 'eval_precision': 0.9734513274336283, 'eval_fbeta_score': 0.9846224466375947, 'eval_runtime': 75.5417, 'eval_samples_per_second': 23.51, 'eval_steps_per_second': 2.939, 'epoch': 1.0}\n",
      "{'loss': 0.0018, 'learning_rate': 3.331664998331665e-05, 'epoch': 1.0}\n",
      "{'loss': 0.0012, 'learning_rate': 2.914581247914581e-05, 'epoch': 1.25}\n",
      "{'loss': 0.0013, 'learning_rate': 2.4974974974974976e-05, 'epoch': 1.5}\n",
      "{'loss': 0.0009, 'learning_rate': 2.080413747080414e-05, 'epoch': 1.75}\n"
     ]
    }
   ],
   "source": [
    "#reinitialize the model\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    CFG.model_name, num_labels=len(CFG.id2label), id2label=CFG.id2label, label2id=CFG.label2id\n",
    ")\n",
    "\n",
    "CFG.training_args.output_dir = os.path.join(CFG.target_dir, 'trainer_combined')\n",
    "\n",
    "#train the model on the combined dataset\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=CFG.training_args,\n",
    "    train_dataset=combined_train_data,\n",
    "    eval_dataset=combined_val_data,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=partial(compute_metrics, labels_list=CFG.LABELS_LIST),\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = os.path.join(CFG.target_dir, 'model_combined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/projet-en-tal/lib/python3.11/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(model_save_path)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    compute_metrics=partial(compute_metrics, labels_list=CFG.LABELS_LIST),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating the model on the combined test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b4ac3532af3439fbe30fbc9ea9a8974",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/247 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.0008544130250811577,\n",
       " 'eval_recall': 0.9930605987250868,\n",
       " 'eval_precision': 0.9943443483881393,\n",
       " 'eval_fbeta_score': 0.993109912415193,\n",
       " 'eval_runtime': 77.9286,\n",
       " 'eval_samples_per_second': 25.344,\n",
       " 'eval_steps_per_second': 3.17}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(combined_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07becd2955c04b659c8951c047b8e91d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/177 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.0009300351957790554,\n",
       " 'eval_recall': 0.8112244897959183,\n",
       " 'eval_precision': 0.8548387096774194,\n",
       " 'eval_fbeta_score': 0.8128195045222177,\n",
       " 'eval_runtime': 52.5997,\n",
       " 'eval_samples_per_second': 26.863,\n",
       " 'eval_steps_per_second': 3.365}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(kaggle_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
